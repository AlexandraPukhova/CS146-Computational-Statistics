{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-class work\n",
    "Below is the data set from 6 medical trials on the effect of specific allergen immunotherapy (SIT) on eczema patients.\n",
    "\n",
    "| Study          | TG improved      | TG not improved   | CG improved    | CG not improved   |\n",
    "|:-------------- | --------:| ------:| ------:| ------:|\n",
    "| Di Rienzo 2014 | 20       | 3      | 9      | 6      |\n",
    "| Galli 1994     | 10       | 6      | 11     | 7      |\n",
    "| Kaufman 1974   | 13       | 3      | 4      | 6      |\n",
    "| Qin 2014       | 35       | 10     | 21     | 18     |\n",
    "| Sanchez 2012   | 22       | 9      | 12     | 17     |\n",
    "| Silny 2006     | 7        | 3      | 0      | 10     |\n",
    "| **Totals**     | **107**  | **34** | **57** | **64** |\n",
    "\n",
    "* TG = Treatment group\n",
    "* CG = Control group\n",
    "\n",
    "The model we used was that each trial's results were generated from a binomial distribution over the number of improved patients with a common improvement rate parameter shared between all trials.\n",
    "\n",
    "For the treatment group we use a subscript $t$:\n",
    "\n",
    "$$\\begin{align}\n",
    "k_{ti} &\\sim \\text{Binomial}(n_{ti}, p_t) \\qquad i=1,2,\\ldots 6\\\\\n",
    "p_t &\\sim \\text{Beta}(\\alpha=1, \\beta=1)\n",
    "\\end{align}$$\n",
    "\n",
    "For the control group we use a subscript $c$:\n",
    "\n",
    "$$\\begin{align}\n",
    "k_{ci} &\\sim \\text{Binomial}(n_{ci}, p_c) \\qquad i=1,2,\\ldots 6\\\\\n",
    "p_c &\\sim \\text{Beta}(\\alpha=1, \\beta=1)\n",
    "\\end{align}$$\n",
    "\n",
    "So we have the same model structure for the treatment and control groups, just with different data.\n",
    "\n",
    "The code below implements the Stan model for the scenario above.\n",
    "\n",
    "* Carefully **read through the code**, including all comments, to understand how Stan is used to represent the medical trial model.\n",
    "* **Run the code** to see inference results for the treatment group.\n",
    "* **Complete the two tasks** at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pystan\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Stan we provide all known quantities as data, namely the observed data\n",
    "# and our prior hyperparameters.\n",
    "eczema_data = {\n",
    "    'treatment': {\n",
    "        'alpha': 1,  # fixed prior hyperparameters for the\n",
    "        'beta': 1,   # beta distribution\n",
    "        'num_trials': 6,  # number of trials in the data set\n",
    "        'patients': [23, 16, 16, 45, 31, 10],  # number of patients per trial\n",
    "        'improved': [20, 10, 13, 35, 22, 7]},  # number of improved patients per trial\n",
    "    'control': {\n",
    "        'alpha': 1,\n",
    "        'beta': 1,\n",
    "        'num_trials': 6,\n",
    "        'patients': [15, 18, 10, 39, 29, 10],\n",
    "        'improved': [9, 11, 4, 21, 12, 0]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below is the Stan code for the medical trial data set. Note that the Stan\n",
    "# code is a string that is passed to the StanModel object below.\n",
    "\n",
    "# We have to tell Stan what data to expect, what our parameters are and what\n",
    "# the likelihood and prior are. Since the posterior is just proportional to\n",
    "# the product of the likelihood and the prior, we don't distinguish between\n",
    "# them explicitly in the model below. Every distribution we specify is\n",
    "# automatically incorporated into the product of likelihood * prior.\n",
    "\n",
    "stan_code = \"\"\"\n",
    "\n",
    "// The data block contains all known quantities - typically the observed\n",
    "// data and any constant hyperparameters.\n",
    "data {  \n",
    "    int<lower=1> num_trials;  // number of trials in the data set\n",
    "    int<lower=0> patients[num_trials];  // number of patients per trial\n",
    "    int<lower=0> improved[num_trials];  // number of improved patients per trial\n",
    "    real<lower=0> alpha;  // fixed prior hyperparameter\n",
    "    real<lower=0> beta;   // fixed prior hyperparameter\n",
    "}\n",
    "\n",
    "// The parameters block contains all unknown quantities - typically the\n",
    "// parameters of the model. Stan will generate samples from the posterior\n",
    "// distributions over all parameters.\n",
    "parameters {\n",
    "    real<lower=0,upper=1> p;  // probability of improvement - the\n",
    "                              // parameter of the binomial likelihood\n",
    "}\n",
    "\n",
    "// The model block contains all probability distributions in the model.\n",
    "// This of this as specifying the generative model for the scenario.\n",
    "model {\n",
    "    p ~ beta(alpha, beta);  // prior over p\n",
    "    for(i in 1:num_trials) {\n",
    "        improved[i] ~ binomial(patients[i], p);  // likelihood function\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell takes a while to run. Compiling a Stan model will feel slow even\n",
    "# on simple models, but it isn't much slower for really complex models. Stan\n",
    "# is translating the model specified above to C++ code and compiling the C++\n",
    "# code to a binary that it can executed. The advantage is that the model needs\n",
    "# to be compiled only once. Once that is done, the same code can be reused\n",
    "# to generate samples for different data sets really quickly.\n",
    "\n",
    "stan_model = pystan.StanModel(model_code=stan_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the model to the data. This will generate samples from the posterior over\n",
    "# all parameters of the model. We start by computing posteriors for the treatment\n",
    "# data.\n",
    "\n",
    "stan_results = stan_model.sampling(data=eczema_data['treatment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_4822bea325d0250e03828b3bc1bb8bdd.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "p      0.76  8.9e-4   0.03   0.69   0.74   0.76   0.78   0.82 1559.0    1.0\n",
      "lp__ -80.07    0.02    0.7 -82.15  -80.2  -79.8 -79.63 -79.58 1862.0    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Mon Oct  8 13:51:31 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "# Print out the mean, standard deviation and quantiles of all parameters.\n",
    "# These are approximate values derived from the samples generated by Stan.\n",
    "# You can ignore the \"lp__\" row for now. Pay attention to the row for\n",
    "# the \"p\" parameter of the model.\n",
    "#\n",
    "# The columns in the summary are\n",
    "#\n",
    "#  * mean: The expected value of the posterior over the parameter\n",
    "#  * se_mean: The estimated error in the posterior mean\n",
    "#  * sd: The standard deviation of the posterior over the parameter\n",
    "#  * 2.5%, etc.: Percentiles of the posterior over the parameter\n",
    "#  * n_eff: The effective number of samples generated by Stan. The\n",
    "#           larger this value, the better.\n",
    "#  * Rhat: An estimate of the quality of the samples. This should be\n",
    "#          close to 1.0, otherwise there might be a problem with the\n",
    "#          convergence of the sampler.\n",
    "\n",
    "print(stan_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_4822bea325d0250e03828b3bc1bb8bdd.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "    mean se_mean     sd   2.5%    50%  97.5%  n_eff   Rhat\n",
      "p   0.76  8.9e-4   0.03   0.69   0.76   0.82 1559.0    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Mon Oct  8 13:51:31 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "# Specify which parameters you want to see in the summary table using\n",
    "# the \"pars\" keyword argument. Specify which percentiles you want to\n",
    "# see using the \"probs\" keyword argument.\n",
    "#\n",
    "# The statement below shows only the 2.5, 50, 97.5 percentiles for the\n",
    "# parameter p.\n",
    "\n",
    "print(stan_results.stansummary(pars=['p'], probs=[0.025, 0.5, 0.975]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can extract the samples generated by Stan so that we\n",
    "# can plot them or calculate any other functions or expected values\n",
    "# we might be interested in.\n",
    "\n",
    "posterior_samples = stan_results.extract()\n",
    "plt.hist(posterior_samples['p'], bins=50, normed \n",
    "         =True)\n",
    "plt.title('Sampled posterior probability density for p')\n",
    "print(\n",
    "    \"Posterior 95% confidence interval for p:\",\n",
    "    np.percentile(posterior_samples['p'], [2.5, 97.5]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "* Reuse the code above to calculate the posterior 95% confidence interval for the probability of improvement in the **control group**.\n",
    "* Plot the posterior histograms of the probability of improvement in the treatment and control groups on the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stan_results_control = stan_model.sampling(data=eczema_data['control'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#posterior_samples = stan_results.extract()\n",
    "posterior_samples_control = stan_results_control.extract()\n",
    "\n",
    "plt.hist(posterior_samples['p'], bins=50, normed=True)\n",
    "plt.hist(posterior_samples_control['p'], bins=50, normed=True)\n",
    "\n",
    "plt.title('Sampled posterior probability density for p')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "* Using the samples from the treatment and control group posteriors, estimate the probability that treatment is at least 19% (in absolute terms) better than control, $P(p_t > p_c + 0.19)$. We computed this result in Session 3.2 where we solved the same model analytically using the algebra of conjugate distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# P of 19% better\n",
    "#sample_size = 1000000\n",
    "#placebo_effect = posterior_control.rvs(size=sample_size)  \n",
    "#treatment_effect = posterior_treatment.rvs(size=sample_size)\n",
    "#print(\"19% better:\")\n",
    "#print((treatment_effect > placebo_effect + 0.19).sum()/sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# P of 19% better\n",
    "sample_size = 4000\n",
    "print(\"19% better:\")\n",
    "print((posterior_samples['p'] > posterior_samples_control['p'] + 0.19).sum()/sample_size)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda]",
   "language": "python",
   "name": "Python [anaconda]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
